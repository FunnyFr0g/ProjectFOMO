{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T11:00:51.415764Z",
     "start_time": "2025-09-16T11:00:51.412476Z"
    }
   },
   "source": [
    "\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=UYT7CN4QVOORGQHYBKIC17B9SQUWOP\n",
    "%env CLEARML_API_SECRET_KEY=L06BUQ4bFm7nNmd3wHK-kDmC0H6i7HnYqKAOGaKuCCF3cCEi1FTJTGh0dABiOgCQY8c"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=UYT7CN4QVOORGQHYBKIC17B9SQUWOP\n",
      "env: CLEARML_API_SECRET_KEY=L06BUQ4bFm7nNmd3wHK-kDmC0H6i7HnYqKAOGaKuCCF3cCEi1FTJTGh0dABiOgCQY8c\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:42:13.954235Z",
     "start_time": "2025-09-16T11:42:13.951767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from clearml import Task, Logger, Dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "# from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "id": "6c5bcf9cd5d40ff0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T15:59:53.073681Z",
     "start_time": "2025-09-16T15:59:39.362828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = Task.init(\n",
    "    project_name='ClearML_Test',\n",
    "    task_name='FOMO_demo',\n",
    "    tags=['FOMO','COCO'])"
   ],
   "id": "d98e9d829b124c3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=42f8ab481ee049f1a42988b74831656f\n",
      "ClearML results page: https://app.clear.ml/projects/24b0dddf967044f1a094d8741c542925/experiments/42f8ab481ee049f1a42988b74831656f/output/log\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загрузим датасет на ClearML",
   "id": "5e74a6b0c5268e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:51:12.919891Z",
     "start_time": "2025-09-16T11:42:15.812710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = Dataset.create(\n",
    "    dataset_name='FOMO_SOD_train',\n",
    "    dataset_project='ClearML_Test',\n",
    "    description = 'фото 224х224 кропнутые из открытого датасета MVA23 с COCO разметкой'\n",
    ")\n",
    "\n",
    "train_path = r'X:\\SOD\\MVA2023SmallObjectDetection4SpottingBirds\\data\\mva2023_sod4bird_train_FOMO\\train\\images'\n",
    "train_ann_path = r'X:\\SOD\\MVA2023SmallObjectDetection4SpottingBirds\\data\\mva2023_sod4bird_train_FOMO\\mva23_FOMO_train.json'\n",
    "dataset.add_files(path=train_path, dataset_path='train/images')\n",
    "dataset.add_files(path=train_ann_path, dataset_path='train/train_annotations')\n",
    "\n",
    "val_path = r'X:\\SOD\\MVA2023SmallObjectDetection4SpottingBirds\\data\\mva2023_sod4bird_train_FOMO\\val\\images'\n",
    "val_ann_path = r'X:\\SOD\\MVA2023SmallObjectDetection4SpottingBirds\\data\\mva2023_sod4bird_train_FOMO\\mva23_FOMO_val.json'\n",
    "dataset.add_files(path=val_path, dataset_path='val/images')\n",
    "dataset.add_files(path=val_ann_path, dataset_path='val/val_annotations')\n",
    "\n",
    "dataset.upload(compression=False)\n",
    "dataset.finalize()"
   ],
   "id": "e77baeb067b2e753",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: https://app.clear.ml/projects/1222bc0e1851409a98e1ec4f61071118/experiments/b8a609f71dd347a59ed298538fbc8195/output/log\n",
      "ClearML dataset page: https://app.clear.ml/datasets/simple/1222bc0e1851409a98e1ec4f61071118/experiments/b8a609f71dd347a59ed298538fbc8195\n",
      "Generating SHA2 hash for 7531 files\n",
      "Hash generation completed\n",
      "Generating SHA2 hash for 767 files\n",
      "Hash generation completed\n",
      "Uploading dataset changes (8300 files compressed to 50.02 MiB) to https://files.clear.ml\n",
      "File compression and upload completed: total size 50.02 MiB, 1 chunk(s) stored (average size 50.02 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FOMO",
   "id": "408faad487498e45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T16:00:28.834363Z",
     "start_time": "2025-09-16T16:00:28.831324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from clearml import Dataset as CML_Dataset"
   ],
   "id": "fca3fb02d24980b4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:02:24.017416Z",
     "start_time": "2025-09-16T18:02:07.672559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 0. Dataset ---\n",
    "# Пути к данным COCO\n",
    "coco_dataset = CML_Dataset.get(dataset_name=\"FOMO_SOD_train\", dataset_project=\"ClearML_Test\")\n",
    "dataset_path = coco_dataset.get_local_copy()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dataset loadeddd\")"
   ],
   "id": "4c84f93af0e97378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loadeddd\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:05:50.526837Z",
     "start_time": "2025-09-16T18:05:50.524521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TRAIN_ANNOTATION_FILE = f\"{dataset_path}/train/train_annotations/mva23_FOMO_train.json\"\n",
    "TRAIN_IMAGE_DIR = f\"{dataset_path}/train/images\"\n",
    "VAL_ANNOTATION_FILE = f\"{dataset_path}/val/val_annotations/mva23_FOMO_val.json\"\n",
    "VAL_IMAGE_DIR = f\"{dataset_path}/val/images\""
   ],
   "id": "248df178c1986f05",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:05:56.965484Z",
     "start_time": "2025-09-16T18:05:56.962263Z"
    }
   },
   "cell_type": "code",
   "source": "print(TRAIN_IMAGE_DIR)",
   "id": "1e839adedc3b330e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ILYA/.clearml/cache/storage_manager/datasets/ds_b8a609f71dd347a59ed298538fbc8195/train/images\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:14:49.944968Z",
     "start_time": "2025-09-16T18:14:48.562688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Конфигурация ---\n",
    "\n",
    "params = {\n",
    "\"NUM_CLASSES\" : 2,  # Кол-во классов (включая фон)\n",
    "\"INPUT_SIZE\" : (224, 224), # Размер входного изображения\n",
    "'BATCH_SIZE' : 8,\n",
    "\"EPOCHS\" : 50,\n",
    "\"LR\" : 1e-3,\n",
    "\"trunkAt\" : 4, # Номер слоя, где обрезать MbileNet. Для карты размером 56 это значение 4\n",
    "}\n",
    "params = task.connect(params)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# --- 2. Датасет COCO ---\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, annotation_file, image_dir, transform=None):\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.cat_ids = self.coco.getCatIds()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Получаем аннотации для изображения\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Создаём маску классов (H, W)\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        for ann in anns:\n",
    "            if ann['category_id'] in self.cat_ids:\n",
    "                class_id = self.cat_ids.index(ann['category_id']) + 1 # 0 - фон\n",
    "                if 'segmentation' in ann:\n",
    "                    # Если есть segmentation, используем его\n",
    "                    mask += self.coco.annToMask(ann) * class_id\n",
    "                else:\n",
    "                    # Если нет - создаём маску из bbox\n",
    "                    x, y, w, h = ann['bbox']\n",
    "                    mask[int(y):int(y + h), int(x):int(x + w)] = class_id\n",
    "                    # print(f'{class_id=}')\n",
    "\n",
    "        # Применяем трансформации\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        mask = augmented['mask']  # mask уже [H, W] = [224, 224]\n",
    "\n",
    "        mask = torch.nn.functional.interpolate(\n",
    "            mask.float().unsqueeze(0).unsqueeze(0),  # Добавляем batch и channel [1, 1, 224, 224]\n",
    "            size=(56, 56),  # Новый размер\n",
    "            # size=(112, 112),  # Новый размер\n",
    "            mode='nearest'  # Без интерполяции (сохраняем целые классы)\n",
    "        ).squeeze().long()  # Убираем batch и channel -> [56, 56]\n",
    "\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # print(mask.sum())\n",
    "        # print(img_path)\n",
    "        # plt.imshow(mask.cpu().numpy())\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        return image, mask.long()\n",
    "\n",
    "# Трансформации\n",
    "transform = A.Compose([\n",
    "    A.Resize(params[\"INPUT_SIZE\"][0], params[\"INPUT_SIZE\"][1]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# --- 3. Модель FOMO ---\n",
    "class FomoBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mobilenet = mobilenet_v2(pretrained=True).features[:params['trunkAt']]  # Обрезаем MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n",
    "\n",
    "class FomoHead(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Увеличиваем глубину feature map перед классификацией\n",
    "        self.conv1 = nn.Conv2d(24, 48, kernel_size=3, padding=1)  # 24 -> 48 каналов\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        # Дополнительный свёрточный слой (опционально)\n",
    "        self.conv2 = nn.Conv2d(48, 32, kernel_size=3, padding=1)  # 48 -> 32\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        # Финал: 1x1 свёртка для классификации\n",
    "        self.conv3 = nn.Conv2d(32, num_classes, kernel_size=1)  # [num_classes, 56, 56]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "class FomoModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = FomoBackbone()\n",
    "        self.head = FomoHead(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.head(features)\n",
    "\n",
    "# --- 4. Обучение ---\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    log_dir = r'X:\\SOD\\MVA2023SmallObjectDetection4SpottingBirds\\FOMO'\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "# --- 5. Основной цикл ---\n",
    "def main():\n",
    "    # Загрузка данных\n",
    "    train_dataset = CocoDataset(TRAIN_ANNOTATION_FILE, TRAIN_IMAGE_DIR, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "    val_dataset = CocoDataset(VAL_ANNOTATION_FILE, TRAIN_IMAGE_DIR, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "    # Модель и оптимизатор\n",
    "    model = FomoModel(params[\"NUM_CLASSES\"]).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"LR\"])\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(1, params[\"EPOCHS\"]+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        print(f\"Epoch {epoch+1}/{params['EPOCHS']}, Loss: {train_loss:.4f}\")\n",
    "        if epoch != 0 and epoch%10 ==0:\n",
    "            # Сохранение весов\n",
    "            torch.save(model.state_dict(), f\"FOMO_56_focalloss_{epoch}e_model_weights.pth\")\n",
    "            print(\"Model weights saved!\")\n",
    "\n",
    "print(\"prepare DONE\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ],
   "id": "4ada9d3e0946d149",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare DONE\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:25:39.139952Z",
     "start_time": "2025-09-16T18:14:54.110622Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "7049a933deba50c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILYA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "C:\\Users\\ILYA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\n",
      "Connecting multiple input models with the same name: `mobilenet_v2-b0353104`. This might result in the wrong model being used when executing remotely\n",
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:13<00:00, 70.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.0107\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.0096\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.0091\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 84.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 84.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.0086\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 82.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/50, Loss: 0.0084\n",
      "Model weights saved!\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
