{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Облачный CLEARML",
   "id": "9c2465c7b98ec0c1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T08:19:02.076375Z",
     "start_time": "2025-09-18T08:19:02.046349Z"
    }
   },
   "source": [
    "\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=UYT7CN4QVOORGQHYBKIC17B9SQUWOP\n",
    "%env CLEARML_API_SECRET_KEY=L06BUQ4bFm7nNmd3wHK-kDmC0H6i7HnYqKAOGaKuCCF3cCEi1FTJTGh0dABiOgCQY8c"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=UYT7CN4QVOORGQHYBKIC17B9SQUWOP\n",
      "env: CLEARML_API_SECRET_KEY=L06BUQ4bFm7nNmd3wHK-kDmC0H6i7HnYqKAOGaKuCCF3cCEi1FTJTGh0dABiOgCQY8c\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Локальный ClearML",
   "id": "3fdfd2acd11d6b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:52:11.480217Z",
     "start_time": "2025-09-18T09:52:11.467195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%env CLEARML_WEB_HOST=http://neuro.kbl-kr.ru/\n",
    "%env CLEARML_API_HOST=http://neuro.kbl-kr.ru:8008\n",
    "%env CLEARML_FILES_HOST=http://neuro.kbl-kr.ru:8081/\n",
    "%env CLEARML_API_ACCESS_KEY=W5GHI79KG5PVRRULKY63CK9154OTXB\n",
    "%env CLEARML_API_SECRET_KEY=LL1OCfgO714o693AuAUfEHX9QWUnQ9n-h8en8EbD6oJpa8f8uPCWjXzzvOaaBNCu0h4"
   ],
   "id": "135c04b719e57820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=http://neuro.kbl-kr.ru/\n",
      "env: CLEARML_API_HOST=http://neuro.kbl-kr.ru:8008\n",
      "env: CLEARML_FILES_HOST=http://neuro.kbl-kr.ru:8081/\n",
      "env: CLEARML_API_ACCESS_KEY=W5GHI79KG5PVRRULKY63CK9154OTXB\n",
      "env: CLEARML_API_SECRET_KEY=LL1OCfgO714o693AuAUfEHX9QWUnQ9n-h8en8EbD6oJpa8f8uPCWjXzzvOaaBNCu0h4\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:52:22.425581Z",
     "start_time": "2025-09-18T09:52:13.706067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from clearml import Task, Logger, Dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "# from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "id": "6c5bcf9cd5d40ff0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:31:00.693431Z",
     "start_time": "2025-09-18T09:30:56.404537Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9b9004715e9221c7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:53:12.772216Z",
     "start_time": "2025-09-18T09:53:09.682805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = Task.init(\n",
    "    project_name='SmallObjectDetection',\n",
    "    task_name='FOMO-mva23_train',\n",
    "    tags=['FOMO'])"
   ],
   "id": "d98e9d829b124c3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=2a4882633e4c48dca9d2fa74dad794cb\n",
      "ClearML results page: http://neuro.kbl-kr.ru/projects/fb88cba1422a4d028da40bd2c7fed04f/experiments/2a4882633e4c48dca9d2fa74dad794cb/output/log\n",
      "2025-09-18 12:53:13,544 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "CLEARML-SERVER new package available: UPGRADE to v2.2.0 is recommended!\n",
      "Release Notes:\n",
      "## New Features and Improvements\r\n",
      "\r\n",
      "- Update fixed users password note in apiserver.conf (#284, thanks @djiboshin!)\r\n",
      "- New UI global search including quick filters ([ClearML #1041](https://github.com/allegroai/clearml/issues/1041))\r\n",
      "- Add persistent UI plot properties: Plot settings (e.g. logarithmic/linear scale, hover mode) are retained across project tasks\r\n",
      "- Add option to hide original graph when smoothing is enabled in UI plot ([ClearML #1400](https://github.com/clearml/clearml/issues/1400))\r\n",
      "- Add persistent UI table details view ([ClearML Web #105](https://github.com/clearml/clearml-web/issues/105)) \r\n",
      "- Add search bar to UI Queues table\r\n",
      "\r\n",
      "## Bug Fixes\r\n",
      "\r\n",
      "- Fix embedded UI task comparison plot legends unnecessarily display task ID suffixes ([ClearML #1344](https://github.com/clearml/clearml/issues/1344))\r\n",
      "- Fix UI task dataset alias does not link to dataset page ([ClearML #735](https://github.com/clearml/clearml/issues/735))\r\n",
      "- UI task comparison parallel coordinate view: \r\n",
      "  - Fix color selector in legend does not display currently assigned color\r\n",
      "  - Fix embedded plot does not display plot legend\r\n",
      "  - Fix full screen missing legend and title, and displaying all graphs in same color\r\n",
      "- UI Plots:\r\n",
      "  - Fix x-axis units are not updated after selection is modified\r\n",
      "  - Fix UI plot \"Show closest data\" toggle not displaying in Plotly 2D and 3D scatter plots\r\n",
      "  - Fix highlight lines for \"show closest data\" function in UI 3D plot difficult to see in dark mode\r\n",
      "  - Fix plotly pointcloud is displayed monochromatically in UI plots ([ClearML #1428](https://github.com/clearml/clearml/issues/1428))\r\n",
      "  - Fix embedded plots sometimes fail to display\r\n",
      "- Queues:\r\n",
      "  - Fix UI queue creation modal allows invalid display name input \r\n",
      "  - Fix queue display name is updated after modification in UI Orchestration > Queues page\r\n",
      "- Fix project path indicator not displaying in UI project card's \r\n",
      "- Fix refreshing UI Model Endpoints > Loading tab navigates to another tab\r\n",
      "- Fix UI Dataset navigation bar sometimes disappears\r\n",
      "- Fix UI object table is sometimes not displayed in info panel view\r\n",
      "- Fix UI Settings API credential labels sometimes disappear \r\n",
      "- Fix default output destination indicator not displaying in UI project cards \r\n",
      "- Fix \"Clear Filters\" functionality sometimes does not work in UI task scalar comparison\r\n",
      "- Fix UI report preview sometimes does not load\r\n",
      "- Fix UI tables' Project column filter does not list all projects\r\n",
      "- Fix UI \"Create Project\" modal sometimes allows for creation of project with invalid date\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:50:13.292649Z",
     "start_time": "2025-09-18T09:50:12.310361Z"
    }
   },
   "cell_type": "code",
   "source": "task = Task.get_task(task_id='2a4882633e4c48dca9d2fa74dad794cb')",
   "id": "dad22586e01270b5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:49:28.597055Z",
     "start_time": "2025-09-18T09:49:28.588109Z"
    }
   },
   "cell_type": "code",
   "source": "task.close()",
   "id": "99eea46c053f162b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FOMO",
   "id": "408faad487498e45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:53:37.333124Z",
     "start_time": "2025-09-18T09:53:32.613113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from clearml import Dataset as CML_Dataset"
   ],
   "id": "fca3fb02d24980b4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-18T09:57:42.821402Z"
    }
   },
   "cell_type": "code",
   "source": "task.execute_remotely(queue_name='default', exit_process=True)",
   "id": "e149b2b8c15756d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switching to remote execution, output log page http://neuro.kbl-kr.ru/projects/fb88cba1422a4d028da40bd2c7fed04f/experiments/2a4882633e4c48dca9d2fa74dad794cb/output/log\n",
      "ClearML Terminating local execution process - continuing execution remotely\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:53:48.765074Z",
     "start_time": "2025-09-18T09:53:39.783658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 0. Dataset ---\n",
    "# Пути к данным COCO\n",
    "coco_dataset = CML_Dataset.get(dataset_name=\"FOMO-mva23\", dataset_project=\"SmallObjectDetection\")\n",
    "dataset_path = coco_dataset.get_local_copy()\n",
    "\n",
    "# dataset_path = r'C:/Users/ILYA/.clearml/cache/storage_manager/datasets/ds_b8a609f71dd347a59ed298538fbc8195/train/images'\n",
    "\n",
    "print(\"Dataset loadeddd\")"
   ],
   "id": "4c84f93af0e97378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:53:39,787 - clearml - INFO - Dataset.get() did not specify alias. Dataset information will not be automatically logged in ClearML Server.\n",
      "2025-09-18 12:53:40,918 - clearml.storage - INFO - Downloading: 49.54MB from http://neuro.kbl-kr.ru:8081/SmallObjectDetection/.datasets/FOMO-mva23/FOMO-mva23.b2fb40384bad494d88e1b6340553c4a4/artifacts/data/dataset.b2fb40384bad494d88e1b6340553c4a4.m3ho3y2i.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "███████████████████████████████ 100% | 49.54/49.54 MB [00:01<00:00, 46.07MB/s]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:53:42,008 - clearml.storage - INFO - Downloaded 49.54 MB successfully from http://neuro.kbl-kr.ru:8081/SmallObjectDetection/.datasets/FOMO-mva23/FOMO-mva23.b2fb40384bad494d88e1b6340553c4a4/artifacts/data/dataset.b2fb40384bad494d88e1b6340553c4a4.m3ho3y2i.zip , saved to C:/Users/ILYA/.clearml/cache/storage_manager/datasets/f4885cd577703322b7ce61436361380b.dataset.b2fb40384bad494d88e1b6340553c4a4.m3ho3y2i.zip\n",
      "Dataset loadeddd\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T08:48:19.638570Z",
     "start_time": "2025-09-18T08:48:19.628392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TRAIN_ANNOTATION_FILE = f\"{dataset_path}/train/train_annotations/mva23_FOMO_train.json\"\n",
    "TRAIN_IMAGE_DIR = f\"{dataset_path}/train/images\"\n",
    "VAL_ANNOTATION_FILE = f\"{dataset_path}/val/val_annotations/mva23_FOMO_val.json\"\n",
    "VAL_IMAGE_DIR = f\"{dataset_path}/val/images\""
   ],
   "id": "248df178c1986f05",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T08:22:37.279491Z",
     "start_time": "2025-09-18T08:22:37.273245Z"
    }
   },
   "cell_type": "code",
   "source": "print(TRAIN_IMAGE_DIR)",
   "id": "1e839adedc3b330e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ILYA/.clearml/cache/storage_manager/datasets/ds_b8a609f71dd347a59ed298538fbc8195/train/images/train/images\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T08:47:00.731325Z",
     "start_time": "2025-09-18T08:46:59.269674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Конфигурация ---\n",
    "\n",
    "params = {\n",
    "\"NUM_CLASSES\" : 2,  # Кол-во классов (включая фон)\n",
    "\"INPUT_SIZE\" : (224, 224), # Размер входного изображения\n",
    "'BATCH_SIZE' : 8,\n",
    "\"EPOCHS\" : 10,\n",
    "\"LR\" : 1e-3,\n",
    "\"trunkAt\" : 4, # Номер слоя, где обрезать MobileNet. Для карты размером 56 это значение 4\n",
    "}\n",
    "params = task.connect(params)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# --- 2. Датасет COCO ---\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, annotation_file, image_dir, transform=None):\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.cat_ids = self.coco.getCatIds()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Получаем аннотации для изображения\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Создаём маску классов (H, W)\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        for ann in anns:\n",
    "            if ann['category_id'] in self.cat_ids:\n",
    "                class_id = self.cat_ids.index(ann['category_id']) + 1 # 0 - фон\n",
    "                if 'segmentation' in ann:\n",
    "                    # Если есть segmentation, используем его\n",
    "                    mask += self.coco.annToMask(ann) * class_id\n",
    "                else:\n",
    "                    # Если нет - создаём маску из bbox\n",
    "                    x, y, w, h = ann['bbox']\n",
    "                    mask[int(y):int(y + h), int(x):int(x + w)] = class_id\n",
    "                    # print(f'{class_id=}')\n",
    "\n",
    "        # Применяем трансформации\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        mask = augmented['mask']  # mask уже [H, W] = [224, 224]\n",
    "\n",
    "        mask = torch.nn.functional.interpolate(\n",
    "            mask.float().unsqueeze(0).unsqueeze(0),  # Добавляем batch и channel [1, 1, 224, 224]\n",
    "            size=(56, 56),  # Новый размер\n",
    "            # size=(112, 112),  # Новый размер\n",
    "            mode='nearest'  # Без интерполяции (сохраняем целые классы)\n",
    "        ).squeeze().long()  # Убираем batch и channel -> [56, 56]\n",
    "\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # print(mask.sum())\n",
    "        # print(img_path)\n",
    "        # plt.imshow(mask.cpu().numpy())\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        return image, mask.long()\n",
    "\n",
    "# Трансформации\n",
    "transform = A.Compose([\n",
    "    A.Resize(params[\"INPUT_SIZE\"][0], params[\"INPUT_SIZE\"][1]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# --- 3. Модель FOMO ---\n",
    "class FomoBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mobilenet = mobilenet_v2(pretrained=True).features[:params['trunkAt']]  # Обрезаем MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n",
    "\n",
    "class FomoHead(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Увеличиваем глубину feature map перед классификацией\n",
    "        self.conv1 = nn.Conv2d(24, 48, kernel_size=3, padding=1)  # 24 -> 48 каналов\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        # Дополнительный свёрточный слой (опционально)\n",
    "        self.conv2 = nn.Conv2d(48, 32, kernel_size=3, padding=1)  # 48 -> 32\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        # Финал: 1x1 свёртка для классификации\n",
    "        self.conv3 = nn.Conv2d(32, num_classes, kernel_size=1)  # [num_classes, 56, 56]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "class FomoModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = FomoBackbone()\n",
    "        self.head = FomoHead(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.head(features)\n",
    "\n",
    "# --- 4. Обучение ---\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# --- 5. Основной цикл ---\n",
    "def main():\n",
    "    # Загрузка данных\n",
    "    train_dataset = CocoDataset(TRAIN_ANNOTATION_FILE, TRAIN_IMAGE_DIR, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "    val_dataset = CocoDataset(VAL_ANNOTATION_FILE, TRAIN_IMAGE_DIR, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "    # Модель и оптимизатор\n",
    "    model = FomoModel(params[\"NUM_CLASSES\"]).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"LR\"])\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(1, params[\"EPOCHS\"]+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        print(f\"Epoch {epoch+1}/{params['EPOCHS']}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Логирование метрик\n",
    "        task.get_logger().report_scalar(\n",
    "            title=\"Loss\", series=\"Train\", value=train_loss.item(), iteration=epoch\n",
    "        )\n",
    "\n",
    "        if epoch != 0 and epoch%10 ==0:\n",
    "            # Сохранение весов\n",
    "            torch.save(model.state_dict(), f\"FOMO_56_crossEntropy_{epoch}e_model_weights.pth\")\n",
    "            print(\"Model weights saved!\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"prepare DONE\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ],
   "id": "4ada9d3e0946d149",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# --- 1. Конфигурация ---\u001B[39;00m\n\u001B[32m      3\u001B[39m params = {\n\u001B[32m      4\u001B[39m \u001B[33m\"\u001B[39m\u001B[33mNUM_CLASSES\u001B[39m\u001B[33m\"\u001B[39m : \u001B[32m2\u001B[39m,  \u001B[38;5;66;03m# Кол-во классов (включая фон)\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[33m\"\u001B[39m\u001B[33mINPUT_SIZE\u001B[39m\u001B[33m\"\u001B[39m : (\u001B[32m224\u001B[39m, \u001B[32m224\u001B[39m), \u001B[38;5;66;03m# Размер входного изображения\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m      9\u001B[39m \u001B[33m\"\u001B[39m\u001B[33mtrunkAt\u001B[39m\u001B[33m\"\u001B[39m : \u001B[32m4\u001B[39m, \u001B[38;5;66;03m# Номер слоя, где обрезать MobileNet. Для карты размером 56 это значение 4\u001B[39;00m\n\u001B[32m     10\u001B[39m }\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m params = \u001B[43mtask\u001B[49m.connect(params)\n\u001B[32m     13\u001B[39m DEVICE = torch.device(\u001B[33m'\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# --- 2. Датасет COCO ---\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'task' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:25:39.139952Z",
     "start_time": "2025-09-16T18:14:54.110622Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "7049a933deba50c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILYA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "C:\\Users\\ILYA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\n",
      "Connecting multiple input models with the same name: `mobilenet_v2-b0353104`. This might result in the wrong model being used when executing remotely\n",
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:13<00:00, 70.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.0107\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.0096\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 77.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:12<00:00, 78.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.0091\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 84.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 84.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.0086\n",
      "Model weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 80.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 82.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 942/942 [00:11<00:00, 83.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/50, Loss: 0.0084\n",
      "Model weights saved!\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
